{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Working of a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have looked at where *Deep Learning (DL)* fits into the broader field of AI, and taken a brief look at its history.\n",
    "\n",
    "Before learning about the core of DL, the neural network, we will look at why and when we might want to use DL rather than other, simpler, *Machine Learning (ML)* algorithms.  \n",
    "\n",
    "First of all, DL has additional abilities compared to basic ML algorithms. It automatically learns representations from data without introducing any hand-coded rules or human domain knowledge. For example, to detect apples on a production line using machine learning, you might need to manually code the extraction of particular features like the roundness of an apple, its weight, or color, to help the machine to learn. DL needs no such instructions and can perform this *feature extraction* by itself.\n",
    "\n",
    "Said that, the choice between DL or ML can be based on the data we are analysing:\n",
    "\n",
    "* When the data is small, deep learning algorithms don't perform that well. This is because deep learning algorithms need a large amount of data to extract and *understand* meaning patterns. In this case, a regular machine learning algorithm may deliver more accurate results.\n",
    "\n",
    "* When dealing with linear functions or less complex data, it can be easier and more efficient to consider alternative machine learning algorithms. If data is non-linear and complex, DL may be more suitable.\n",
    "\n",
    "We are now going to see how DL components work, starting with the fundamental building block of deep learning - the *perceptron*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A network may have three types of layers:\n",
    "\n",
    "* **input layers** that take raw input from the domain,\n",
    "\n",
    "* **hidden layers** that take input from another layer and pass output to another layer,\n",
    "\n",
    "* and **output layers** that make a prediction.\n",
    "\n",
    "The *percepton* is a single-layer neural network with four main parameters, i.e., input values, weights and bias, net sum, and activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div> <img src=\"graphics/perceptron.png\" alt=\"Drawing\" style=\"width: 600px;\"/></div></center> \n",
    "\n",
    "The above diagram shows the forward propagation of information through a single neuron. Here the information is defined by its inputs, $x_{1}$, $x_{2}$..$x_{m}$ and their corresponding weights, $w_{m}$, $w_{2}$...$w_{m}$.\n",
    "We can then take the sum of the multiplication of the inputs and their respective weights (i.e., linear combination of inputs). A bias input is added to the summation, $Bias$ or $b$.\n",
    "\n",
    "This calculation results in a single number, which is fed to the activation function, where it generates the output. The bias value allows to shift the activation function regardless of the input, similar to the role of a constant $c$ in a linear function $y = mx+c$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above forward propagation can be represented mathematically with the below function. \n",
    "<center><div> <img src=\"graphics/perceptron_equation.png\" alt=\"Drawing\" style=\"width: 300px;\"/></div> </center>\n",
    "\n",
    "Furthermore, we can use linear algebra to represent the linear combination of the inputs and its weight in vector format, and simply take the dot product of $X^{T}W$ to get the same result. \n",
    "<center><div> <img src=\"graphics/perceptron_equation_simplified.png\" alt=\"Drawing\" style=\"width: 300px;\"/></div> </center>\n",
    "\n",
    "We now dive into the activation function and its use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 2 Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An *Activation Function* in a neural network decides the output value of a neuron. The choice of activation function has a large impact on the capability and performance of the neural network: the activation function in the *hidden layer* controls how well the network model learns the training dataset, while that on the *output layer* defines the type of predictions the model can make.\n",
    "\n",
    "The same activation function is usually used on all hidden layers, with a different activation function on the output layer; the choice on the latter depends on the type of prediction required by the model.\n",
    "\n",
    "Activation functions can be linear or non-linear. By using a non-linear activation function in the hidden layers of a neural network, the network can learn more complex patterns within the data.\n",
    "\n",
    "<center><div> <img src=\"graphics/non_linear_function.png\" alt=\"Drawing\" style=\"width: 700px;\"/></div> </center>\n",
    "\n",
    "In addition, neural networks are typically trained using the backpropagation of error algorithm that requires the derivative of a *'prediction error'* in order to update the weights of the model. Because of that, non-linear activation function is preferred. Let's have a look at an example.\n",
    "\n",
    "If we consider the linear function $y = x+c$, the calculated gradient for any neuron output would be the same, i.e., $1$.\n",
    "Therefore, we cannot apply backpropagation to find how the neuron weights should change based on the calculated error. Additionally, using linear activations would result in our model becomes a linear model because multiple linear functions chained together is still only considered to be a linear function. This would suggest that a linear activation function is not ideal, particularly when working with non-linear data.\n",
    "\n",
    "<center><div> <img src=\"graphics/linear_function_gradient.png\" alt=\"Drawing\" style=\"width: 400px;\"/></div> </center> \n",
    "\n",
    "Depending on the use case, we can use various non-linear activation functions. Among the most used:\n",
    "\n",
    "* Rectified Linear Activation Function\n",
    "\n",
    "* Sigmoid (or Logistic) Activation Function\n",
    "\n",
    "* Tanh Hidden Layer Activation Function\n",
    "\n",
    "Let's now have a quick look at them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Rectified Linear Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rectified linear activation function is a piecewise (or hinge) linear function, meaning that it is linear for half of the input domain and non-linear for the other half. More specifically, it is linear for values greater than $0$ where it returns the value provided as input directly, and it is non-linear for values equal-to or less than $0$, for which it returns $0$. \n",
    "\n",
    "Below is the formula for the ReLu function:\n",
    "\n",
    "$$g(z) = max(z;0)$$\n",
    "\n",
    "and its graphical representation.\n",
    "\n",
    "<center><div> <img src=\"graphics/relu_function.png\" alt=\"Drawing\" style=\"width: 400px;\"/></div></center>\n",
    "\n",
    "A node or unit that implements this activation function is referred to as a rectified linear activation unit, or ReLU for short. Often, networks that use the rectifier function for the hidden layers are referred to as rectified networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Sigmoid (or Logistic) Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Sigmoid Activation Function* takes any real value as input and outputs values in the range $[0; 1]$. The larger the input (in the positive direction), the closer the output value is to $1$. And the smaller the input (in the negative direction), the closer the output to $0$.\n",
    "\n",
    "Below is the formula of the sigmoid activation:\n",
    "\n",
    "$$σ(x) = \\frac{1}{(1 + e^{-x})}$$\n",
    "\n",
    "and its graphical representation.\n",
    "\n",
    "<center><div> <img src=\"graphics/sigmoid_function.png\" alt=\"Drawing\" style=\"width: 400px;\"/></div></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3. Tanh Hidden Layer Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Tanh Hidden Layer Activation Function* takes any real value as input and outputs values in the range $[-1; 1]$. The larger the input (in the positive direction), the closer the output value to $1$. The smaller the input (in the negative direction), the closer the output is to $-1$.\n",
    "\n",
    "Below is the formula of the Tanh activation function:\n",
    "\n",
    "$$tanh(x) = \\frac{(e^{x} – e^{-x})}{(e^{x} + e^{-x})}$$\n",
    "\n",
    "and its graphical representation.\n",
    "\n",
    "<center><div> <img src=\"graphics/tanh_function.png\" alt=\"Drawing\" style=\"width: 400px;\"/></div></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Shallow Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our understanding of the *perceptron* and create a *Shallow Neural Network*, characterised by a single hidden layer with multiple neurons (bias has been ignored for simplicity), that feed into an output layer. This differs from a *Deep Neural Network*, which characterised by several hidden layers (often of various types).\n",
    "\n",
    "<center><div> <img src=\"graphics/shallow_nn_1.png\" alt=\"Drawing\" style=\"width: 700px;\"/></div></center> \n",
    "\n",
    "The layer is *'hidden'* as its state is not directly observable, whereas the input and the output layers are directly observable. We can probe to find the state, but they are learned rather than enforced (we will discuss this later).\n",
    "\n",
    "There are two transformation processes with their respective weight matrices denoted as $W^{\\left( 1\\right) }$ (between the input and hidden layers) and $W^{\\left( 2\\right) }$ (between the hidden and output layers).\n",
    "\n",
    "We can then perform a single perceptron computation in the hidden layer with\n",
    "$z_{i}=w_{0,j}^{\\left( 1\\right) }+\\sum ^{m}_{j=1}x_{j}w_{j,i}^{\\left( 1\\right) }$. This computation is the weighted sum of all of its inputs, transformed by a non-linearity function($g\\left( z_{i}\\right)$). The result is then passed on to an output layer node which is calculated in a similar manner: $\\widehat{y}_{i}=g\\left( w_{0,i}^{\\left( 2\\right) }+\\sum ^{d}_{j=1}z_{j}w_{j,i}^{\\left( 2\\right) }\\ \\right)$.\n",
    "\n",
    "For demonstration, $z_2$:\n",
    "\n",
    "<center><div> <img src=\"graphics/shallow_nn_example.png\" alt=\"Drawing\" style=\"width: 700px;\"/></div> </center>\n",
    "\n",
    "$$z_{2}=w_{0,2}^{\\left( 1\\right) }+\\sum ^{m}_{j=1}x_{j}w_{j,2}^{\\left( 1\\right) }$$\n",
    "\n",
    "$$z_{2}=w_{0,2}^{\\left(1\\right)}+ x_1w_{1,2}^{\\left( 1\\right)} + x_2w_{2,2}^{\\left( 1\\right)}  + x_mw_{m,2}^{\\left( 1\\right)}  $$\n",
    "\n",
    "The same process is repeated for every neuron in the hidden layer and their results are forward propagated as an input to the nodes in the next layer (in this case the output layer). We will going to demonstrate this with an example in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Shallow Neural Network Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div> <img src=\"graphics/shallow_nn_applied.png\" alt=\"Drawing\" style=\"width: 700px;\"/></div> </center>\n",
    "\n",
    "In this example we are trying to predict the propability of someone understanding deep learning based on two features:\n",
    "\n",
    "1. The number of courses a person has completed.\n",
    "\n",
    "2. The average number of hours spent on each course.\n",
    "\n",
    "Our example input is *2* courses and an average of *3* hours spent on each course. \n",
    "\n",
    "<center><div> <img src=\"graphics/shallow_nn_applied_2.png\" alt=\"Drawing\" style=\"width: 750px;\"/></div> </center>\n",
    "\n",
    "You can see that our network is not very good at predicting the correct probability. That is due to the fact that our network weights are completely randomised as the network has not yet been trained. To improve the prediction, we need to find weights so that the $Error$ is reduced to nearly *0*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the model to correct itself, it will need to find a way to measure its error. This is defined as the loss of the network, which measures the difference between predictions and actual values. Note that $f(x)$ below denotes the final model output for input values, $x$.\n",
    "\n",
    "<center><div> <img src=\"graphics/loss_function.png\" alt=\"Drawing\" style=\"width: 250px;\"/></div> </center>\n",
    "\n",
    "The input to the loss function are the $Prediction$ and the $Actual$ values. The closer the difference between those values, the better the model - it is therefore  necessary to try and minimise the loss $L$.\n",
    "\n",
    "The empirical loss $J(W)$ (also known as the cost function) measures the total average loss across all of our data points, not just one sample. It is computed by finding the mean of the loss of all our data points and their respective predictions.\n",
    "\n",
    "<center><div> <img src=\"graphics/cost_function.png\" alt=\"Drawing\" style=\"width: 650px;\"/></div> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to train the network using the loss function to find the weights $W^*$ that achieve the lowest loss. This can be mathematically represented as such:\n",
    "\n",
    "$$W^{\\ast }=\\argmin_{W}\\dfrac{1}{n}\\sum ^{n}_{i=1}L\\left( f\\left( x^{\\left( i\\right) };W\\right) ,y^{\\left( i\\right) }\\right)$$\n",
    "$$W^{\\ast }=\\argmin_{W}J\\left( W\\right)$$\n",
    "$$W=\\left\\{ W^{\\left( 0\\right) },W^{\\left( 1\\right) },\\ldots \\right\\}$$\n",
    "\n",
    "$W$ is the collection of all the weights across all layers. \n",
    "\n",
    "The loss can be described as a function of our weights, and for the purposes of visualisation, the loss landscape created across two weights $w_{0}$ and $w_{1}$ would look like this:\n",
    "\n",
    "<center><div> <img src=\"graphics/parameter_landscape.png\" alt=\"Drawing\" style=\"width: 500px;\"/></div> </center>\n",
    "\n",
    "This landscape shows us the loss that is expected for all varitions of $w_{0}$ and $w_{1}$. The whole process of training the model is to establish the optimal $w_{0}$ and $w_{1}$, i.e., $ W^{\\ast }$ that would provide the lowest loss. \n",
    "\n",
    "The best way to do that is by randomly picking a point $(w_{0},w_{1})$ in the landscape. At that point, we need to determine the slope of the angle of our $J(W)$ to understand if we are headed in the right direction. A negative slope means that we are headed downward, while a posive slope means that we moved beyond the minimum. To determine the slope, we compute the gradient of the function on that point, $\\dfrac{\\partial J\\left( W\\right) }{\\partial W}$. Given the gradient can be interpreted as the direction and rate of fastest increase, we will need to take a small step in the opposite direction to find a lower loss. We repeat this process until convergence, i.e., we hit a local minimum. This process is anologous of letting a ball loose at a random point on a hill and it coming to a stop at the bottom (global minimum) or in a small indent higher up the hill (local minima).\n",
    "\n",
    "<center><div> <img src=\"graphics/global_minimum.png\" alt=\"Drawing\" style=\"width: 500px;\"/></div> </center>\n",
    "\n",
    "Note that it is ulikely to find the global minimum by selecting a single random point. To increase the chance of finding it, we could choose different points of the loss function and follow the same steps for all of them. Such an approach is called *random restart*.\n",
    "\n",
    "The above algorithm is called __Gradient Descent__ and can be summarised as follows:\n",
    "\n",
    "1. Initialize weights randomly.\n",
    "\n",
    "2. Loop until convergence:\n",
    "\n",
    "    2.a. Compute gradient, $\\dfrac{\\partial J\\left( W\\right) }{\\partial W}$.\n",
    "\n",
    "    2.b. Update weights, $W\\leftarrow W-\\alpha\\dfrac{\\partial J\\left( W\\right) }{\\partial W}$.\n",
    "    \n",
    "    2.c. Return weights.\n",
    "\n",
    "Note that $\\alpha$ is the *learning rate*, a factor used to control the speed at which the model learns.\n",
    "\n",
    "The choice of the learning rate is relevant:\n",
    "\n",
    "* Lower learning rates result in smaller changes. Smaller changes may allow the model to learn a more optimal set of weights, but may take longer to train.\n",
    "\n",
    "* Too low learning rates may lead the model to never converge or get stuck on a suboptimal set of weights.\n",
    "\n",
    "* Higher learning rates result in bigger changes. Bigger changes may allow the model to learn faster, at the cost of never converging or arriving on a suboptimal final set of weights\n",
    "\n",
    "* Too large learning rates may result in weights that will be too large and the model will generate divergent oscillations. In this case, gradient descent can inadvertently increase rather than decrease the training error.\n",
    "\n",
    "Therefore, we should be careful to choose a learning rate that is not too small or large. We need to choose the one that allows us to find, on average, a good-enough set of weights.\n",
    "\n",
    "We have now seen how a simple *Shallow Neural Network* is assembled and trained to optimise a model that will yield a prediction with the lowest error. \n",
    "\n",
    "In the next section, we are going to use Python to create a model to predict house prices."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
